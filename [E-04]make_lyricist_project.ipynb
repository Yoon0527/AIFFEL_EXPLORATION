{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4186c84e",
   "metadata": {},
   "source": [
    "# [E-04] 작사가 인공지능 만들기"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c605bcb",
   "metadata": {},
   "source": [
    "* 루브릭 평가기준\n",
    "    * 텍스트 제너레이션 결과가 그럴듯한 문장으로 생성되는가?\n",
    "    * 특수문자 제거, 토크나이저 생성, 패딩 처리 등의 과정이 빠짐없이 진행되었는가?\n",
    "    * 텍스트 생성모델의 validation loss가 2.2 이하로 낮아졌는가?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27ddf528",
   "metadata": {},
   "source": [
    "### 시퀀스"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62957602",
   "metadata": {},
   "source": [
    "* 수열을 영어로 시퀀스라고 함.\n",
    "* 값이 연속적으로 이어진 자료형들을 총칭하여 '시퀀스 자료형'이라고 한다.\n",
    "* 예측을 위해 나열된 자료들이 어느 정도 연관성이 있어야 한다.\n",
    "* 인공지능이 문장을 구성하기 위해 통계에 기반한 방법을 사용한다.\n",
    "    * **인공지능에게 많은 글을 읽게 함으로써 글을 이해하게 한다.**\n",
    "    * 즉, 많은 데이터가 곧 좋은 결과를 만들어낸다.(단어를 적재적소에 활용하는 능력이 발달된다.)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1cf3c7ff",
   "metadata": {},
   "source": [
    "### 순환신경망(RNN)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5256fad3",
   "metadata": {},
   "source": [
    "* 'start' 토큰을 맨 앞에 추가해서 문장을 생성 하라는 신호를 준다.\n",
    "* 생성한 단어를 다시 입력으로 사용하고, 다음 단어를 생성. -> 순환하는 형태\n",
    "* 인공지능이 문장을 다 만들었으면, 'end' 토큰을 생성.\n",
    "* 'start' 토큰이 문장의 시작에 더해진 입력 데이터(문제)와 'end' 토큰이 문장 끝에 더해진 출력 데이터(답)이 필요하다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6bdfd2f",
   "metadata": {},
   "source": [
    "### 언어 모델"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "330600e3",
   "metadata": {},
   "source": [
    "어떤 문구 뒤에 다음 단어가 나올 확률이 높다는 것은 그 단어가 나오는 것이 보다 자연스럽다는 뜻이다.\n",
    "그렇다고해서 '나는' 뒤에 '밥을'이 나오는 게 자연스럽다는 말은 아님. 단지 '나는' 뒤에 올 수 있는 자연스러운 단어의 경우의 수가 너무 많아 불확실성이 높다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db6902b9",
   "metadata": {},
   "source": [
    "* n-1개의 단어 시퀀스 w1~wn-1이 주어졌을 때, n번째 단어 wn으로 뭐가 올지 예측하는 확률 모델을 **언어 모델**이라고 한다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b20dc5eb",
   "metadata": {},
   "source": [
    "* RNN은 w1,...,wn-1이 주어졌을 때 wn으로 뭐가 올지 예측하는 구조를 가지고 있다.\n",
    "    * 어떤 텍스트도 언어 모델의 학습 데이터가 될 수 있다.\n",
    "    * **n-1번째까지의 단어 시퀀스가 x_train, n번째 단어가 y_train이 된다.**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a69302a1",
   "metadata": {},
   "source": [
    "### 데이터 다운로드 및 읽어오기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "35f52689",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "데이터 크기: 187088\n",
      "Examples:\n",
      " [\"Now I've heard there was a secret chord\", 'That David played, and it pleased the Lord', \"But you don't really care for music, do you?\"]\n"
     ]
    }
   ],
   "source": [
    "import os, re\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import glob\n",
    "\n",
    "txt_file_path = os.getenv('HOME')+'/aiffel/lyricist/data/lyrics/*'\n",
    "\n",
    "txt_list = glob.glob(txt_file_path)\n",
    "\n",
    "raw_corpus = []\n",
    "\n",
    "for txt_file in txt_list:\n",
    "    with open(txt_file, \"r\") as f:\n",
    "        raw = f.read().splitlines()\n",
    "        raw_corpus.extend(raw)\n",
    "\n",
    "print(\"데이터 크기:\", len(raw_corpus))\n",
    "print(\"Examples:\\n\", raw_corpus[:3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5096b8af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/aiffel/aiffel/lyricist/data/lyrics/notorious_big.txt /aiffel/aiffel/lyricist/data/lyrics/notorious-big.txt\n",
      "/aiffel/aiffel/lyricist/data/lyrics/Kanye_West.txt /aiffel/aiffel/lyricist/data/lyrics/kanye-west.txt\n"
     ]
    }
   ],
   "source": [
    "# 중복 파일 제거\n",
    "import itertools\n",
    "\n",
    "def check_dup(file1, file2):\n",
    "    txt1 = []\n",
    "    txt2 = []\n",
    "    with open(file1, \"r\", encoding=\"utf-8\") as f:\n",
    "        raw = f.read().splitlines()\n",
    "        txt1.extend(raw)\n",
    "    with open(file2, \"r\", encoding=\"utf-8\") as f:\n",
    "        raw = f.read().splitlines()\n",
    "        txt2.extend(raw)\n",
    "    txt1 = set(txt1)\n",
    "    txt2 = set(txt2)\n",
    "    diff = txt1.difference(txt2)\n",
    "    return len(txt1) * 0.05 > len(diff)\n",
    "\n",
    "\n",
    "for a, b in itertools.combinations(txt_list, 2):\n",
    "    if check_dup(a, b):\n",
    "        print(a, b)\n",
    "        txt_list.remove(b)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d392e7a8",
   "metadata": {},
   "source": [
    "* 지훈님의 중복 파일 제거 코드입니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "074b4109",
   "metadata": {},
   "outputs": [],
   "source": [
    "for idx, sentence in enumerate(raw_corpus):\n",
    "    if len(sentence) == 0: continue # 길이가 0인 문장은 건너뛴다.\n",
    "    if sentence[-1] == ':': continue # 문장의 끝이 :인 문장은 건너뛴다.\n",
    "     \n",
    "    # 출력되는 양이 너무 많아서 주석 처리\n",
    "    #print(sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f761fd2c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<start> this is sample sentence . <end>\n"
     ]
    }
   ],
   "source": [
    "def preprocess_sentence(sentence):\n",
    "    sentence = sentence.lower().strip() #1\n",
    "    sentence = re.sub(r\"([?.!,¿])\", r\" \\1 \", sentence) #2\n",
    "    sentence = re.sub(r'[\" \"]+', \" \", sentence) #3\n",
    "    sentence = re.sub(r\"[^a-zA-Z?.!,¿]+\", \" \", sentence) #4\n",
    "    sentence = sentence.strip() #5\n",
    "    sentence = '<start> ' + sentence + ' <end>' #6\n",
    "    return sentence\n",
    "\n",
    "print(preprocess_sentence(\"This @_is ;;;sample        sentence.\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "76fae82b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['<start> now i ve heard there was a secret chord <end>',\n",
       " '<start> that david played , and it pleased the lord <end>',\n",
       " '<start> but you don t really care for music , do you ? <end>',\n",
       " '<start> it goes like this <end>',\n",
       " '<start> the fourth , the fifth <end>',\n",
       " '<start> the minor fall , the major lift <end>',\n",
       " '<start> the baffled king composing hallelujah hallelujah <end>',\n",
       " '<start> hallelujah <end>',\n",
       " '<start> hallelujah <end>',\n",
       " '<start> hallelujah your faith was strong but you needed proof <end>']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 정제된 단어를 모을 변수\n",
    "corpus = []\n",
    "\n",
    "for sentence in raw_corpus:\n",
    "    #원하지 않는 문장은 건너 뛴다.\n",
    "    if len(sentence) == 0: continue\n",
    "    if sentence[-1] == \":\": continue\n",
    "        \n",
    "    #정제 후 담아줌\n",
    "    preprocessed_sentence = preprocess_sentence(sentence)\n",
    "    corpus.append(preprocessed_sentence)\n",
    "    \n",
    "corpus[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d45087c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[   2   50    5 ...    0    0    0]\n",
      " [   2   17 2639 ...    0    0    0]\n",
      " [   2   36    7 ...   43    3    0]\n",
      " ...\n",
      " [   5   22    9 ...   10 1013    3]\n",
      " [  37   15 9049 ...  877  647    3]\n",
      " [   2    7   34 ...    0    0    0]] <keras_preprocessing.text.Tokenizer object at 0x7f17605aaa90>\n"
     ]
    }
   ],
   "source": [
    "def tokenize(corpus):\n",
    "    tokenizer = tf.keras.preprocessing.text.Tokenizer(\n",
    "        num_words=15000, \n",
    "        filters=' ',\n",
    "        oov_token=\"<unk>\"\n",
    "    )\n",
    "    tokenizer.fit_on_texts(corpus)\n",
    "    tensor = tokenizer.texts_to_sequences(corpus)   \n",
    "\n",
    "    tensor = tf.keras.preprocessing.sequence.pad_sequences(tensor,\n",
    "                                                           padding='post',\n",
    "                                                          maxlen = 15)  \n",
    "    \n",
    "    print(tensor,tokenizer)\n",
    "    return tensor, tokenizer\n",
    "\n",
    "tensor, tokenizer = tokenize(corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f97fe845",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[   2   50    5   91  297   65   57    9  969 6042]\n",
      " [   2   17 2639  873    4    8   11 6043    6  329]\n",
      " [   2   36    7   37   15  164  282   28  299    4]]\n"
     ]
    }
   ],
   "source": [
    "print(tensor[:3, :10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "be2a8aaf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 : <unk>\n",
      "2 : <start>\n",
      "3 : <end>\n",
      "4 : ,\n",
      "5 : i\n",
      "6 : the\n",
      "7 : you\n",
      "8 : and\n",
      "9 : a\n",
      "10 : to\n"
     ]
    }
   ],
   "source": [
    "for idx in tokenizer.index_word:\n",
    "    print(idx, \":\", tokenizer.index_word[idx])\n",
    "\n",
    "    if idx >= 10: break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "070642e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[   2   50    5   91  297   65   57    9  969 6042    3    0    0    0]\n",
      "[  50    5   91  297   65   57    9  969 6042    3    0    0    0    0]\n"
     ]
    }
   ],
   "source": [
    "src_input = tensor[:, :-1]  \n",
    "tgt_input = tensor[:, 1:]    \n",
    "\n",
    "print(src_input[0])\n",
    "print(tgt_input[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8b9b2f16",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<BatchDataset shapes: ((256, 14), (256, 14)), types: (tf.int32, tf.int32)>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "BUFFER_SIZE = len(src_input)\n",
    "BATCH_SIZE = 256\n",
    "steps_per_epoch = len(src_input) // BATCH_SIZE\n",
    "\n",
    "VOCAB_SIZE = tokenizer.num_words + 1   \n",
    "\n",
    "dataset = tf.data.Dataset.from_tensor_slices((src_input, tgt_input))\n",
    "dataset = dataset.shuffle(BUFFER_SIZE)\n",
    "dataset = dataset.batch(BATCH_SIZE, drop_remainder=True)\n",
    "dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1986ae4",
   "metadata": {},
   "source": [
    "### stpe 4. 평가 데이터셋 분리 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e865092f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "enc_train, enc_val, dec_train, dec_val = train_test_split(src_input,\n",
    "                                                          tgt_input,\n",
    "                                                         test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3345bc57",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Source Train: (140599, 14)\n",
      "Target Train: (140599, 14)\n"
     ]
    }
   ],
   "source": [
    "print(\"Source Train:\", enc_train.shape)\n",
    "print(\"Target Train:\", dec_train.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71308917",
   "metadata": {},
   "source": [
    "### 인공지능 만들기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b4988591",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TextGenerator(tf.keras.Model):\n",
    "    def __init__(self, vocab_size, embedding_size, hidden_size):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.embedding = tf.keras.layers.Embedding(vocab_size, embedding_size)\n",
    "        self.rnn_1 = tf.keras.layers.LSTM(hidden_size, return_sequences=True)\n",
    "        self.rnn_2 = tf.keras.layers.LSTM(hidden_size, return_sequences=True)\n",
    "        self.linear = tf.keras.layers.Dense(vocab_size)\n",
    "        \n",
    "    def call(self, x):\n",
    "        out = self.embedding(x)\n",
    "        out = self.rnn_1(out)\n",
    "        out = self.rnn_2(out)\n",
    "        out = self.linear(out)\n",
    "        \n",
    "        return out\n",
    "    \n",
    "embedding_size = 256\n",
    "hidden_size = 1024\n",
    "lyricist= TextGenerator(tokenizer.num_words + 1, embedding_size , hidden_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8a2f5d18",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(256, 14, 15001), dtype=float32, numpy=\n",
       "array([[[ 8.46021503e-05,  2.52009748e-04,  4.61594245e-05, ...,\n",
       "          2.33305516e-04, -7.78254835e-05, -3.36763012e-04],\n",
       "        [ 2.90806842e-04,  1.93902131e-04, -6.48359928e-05, ...,\n",
       "          6.25596789e-04, -2.22000817e-04, -5.48156037e-04],\n",
       "        [ 2.07553079e-04, -9.14896955e-05,  1.41962417e-04, ...,\n",
       "          8.35243263e-04, -1.83566342e-04, -6.53463241e-04],\n",
       "        ...,\n",
       "        [-4.73332533e-04, -6.98791759e-04,  1.10949168e-03, ...,\n",
       "          1.26563871e-04,  9.19126964e-04, -5.34387771e-04],\n",
       "        [-4.29378764e-04, -4.50320076e-04,  1.05934707e-03, ...,\n",
       "          8.65775946e-05,  8.96921207e-04, -1.50823689e-04],\n",
       "        [-3.94241972e-04, -4.98914218e-04,  8.54750164e-04, ...,\n",
       "          1.70037543e-04,  9.50952235e-04,  2.42470463e-07]],\n",
       "\n",
       "       [[-1.42095509e-04,  9.68535824e-06,  6.28962734e-05, ...,\n",
       "          6.63788596e-05,  8.19904744e-05,  2.84427224e-04],\n",
       "        [-1.35691647e-04, -4.09511631e-05, -9.54044299e-05, ...,\n",
       "          2.25724027e-04,  1.70403480e-04,  2.37160129e-04],\n",
       "        [-3.30997718e-04, -1.03652768e-04, -3.05344147e-04, ...,\n",
       "          3.51921219e-04,  3.86875414e-04,  1.22322032e-04],\n",
       "        ...,\n",
       "        [-1.20908988e-03, -1.65453370e-04, -5.20725502e-04, ...,\n",
       "          6.09185139e-04, -3.95574229e-04,  1.03342012e-04],\n",
       "        [-1.61360379e-03, -2.70374061e-04, -7.42752803e-04, ...,\n",
       "          6.64692954e-04, -7.66971323e-04,  3.54517542e-04],\n",
       "        [-2.05108151e-03, -3.82552709e-04, -9.32468800e-04, ...,\n",
       "          7.53750093e-04, -1.11661362e-03,  5.99690189e-04]],\n",
       "\n",
       "       [[-1.42095509e-04,  9.68535824e-06,  6.28962734e-05, ...,\n",
       "          6.63788596e-05,  8.19904744e-05,  2.84427224e-04],\n",
       "        [-4.30481508e-04,  2.54024199e-04,  2.68483418e-04, ...,\n",
       "          2.40096197e-04,  2.40049034e-04,  4.15766408e-04],\n",
       "        [-5.52588259e-04,  6.80300640e-04,  3.59464320e-04, ...,\n",
       "          2.88204581e-04,  3.76325013e-04,  3.30013660e-04],\n",
       "        ...,\n",
       "        [-2.45671661e-04,  5.23263543e-06, -2.81367218e-04, ...,\n",
       "         -9.85640436e-05, -5.57310530e-04, -2.00098642e-04],\n",
       "        [-4.65872115e-04, -1.83496661e-06, -3.64729523e-04, ...,\n",
       "         -9.52082883e-06, -7.70468498e-04, -1.81298150e-04],\n",
       "        [-7.77760521e-04, -2.87806088e-05, -5.14578715e-04, ...,\n",
       "          9.48024608e-05, -1.00971037e-03, -4.21799123e-05]],\n",
       "\n",
       "       ...,\n",
       "\n",
       "       [[-1.42095509e-04,  9.68535824e-06,  6.28962734e-05, ...,\n",
       "          6.63788596e-05,  8.19904744e-05,  2.84427224e-04],\n",
       "        [-2.28531819e-04, -7.15079223e-05,  2.07270612e-04, ...,\n",
       "          2.02996613e-04,  1.87485697e-04,  3.96610500e-04],\n",
       "        [-4.83844997e-05, -2.08659010e-04,  2.38269728e-04, ...,\n",
       "          4.77902213e-05,  1.32599205e-04, -9.31704635e-05],\n",
       "        ...,\n",
       "        [-1.97647582e-03, -2.86969909e-04, -8.76968319e-04, ...,\n",
       "          4.26715706e-04, -1.57378684e-03,  1.48228370e-04],\n",
       "        [-2.48085498e-03, -3.90987319e-04, -1.04026147e-03, ...,\n",
       "          6.48923451e-04, -1.78237574e-03,  4.53607790e-04],\n",
       "        [-2.95883650e-03, -5.03356860e-04, -1.16174540e-03, ...,\n",
       "          8.64084694e-04, -1.96650741e-03,  7.26347789e-04]],\n",
       "\n",
       "       [[ 2.96225247e-04, -1.69254403e-04, -2.27203036e-05, ...,\n",
       "         -9.32505372e-06,  3.09558782e-05,  1.86726887e-04],\n",
       "        [ 3.86341504e-04, -9.12854448e-05,  2.01024013e-04, ...,\n",
       "         -1.80051240e-04,  1.67559163e-04,  1.35058493e-04],\n",
       "        [ 4.30913904e-04, -2.79184955e-04,  2.31222279e-04, ...,\n",
       "         -3.71487753e-04,  1.78525894e-04,  4.52182576e-04],\n",
       "        ...,\n",
       "        [ 4.67567821e-04,  5.37992310e-05, -3.65507498e-04, ...,\n",
       "         -3.13833036e-04,  8.39525455e-05,  2.98650208e-04],\n",
       "        [ 3.50230956e-04,  2.51576857e-04, -2.87522009e-04, ...,\n",
       "         -1.92772539e-04, -5.40869587e-05,  4.25310893e-04],\n",
       "        [ 3.53967538e-04,  3.79248988e-04, -3.89065623e-04, ...,\n",
       "         -2.87394592e-04,  1.40907257e-04,  5.80326130e-04]],\n",
       "\n",
       "       [[-1.42095509e-04,  9.68535824e-06,  6.28962734e-05, ...,\n",
       "          6.63788596e-05,  8.19904744e-05,  2.84427224e-04],\n",
       "        [-2.49488835e-06, -1.29822365e-05, -1.39431344e-04, ...,\n",
       "          9.43120322e-05,  1.17486532e-04,  2.82127177e-04],\n",
       "        [ 2.80737499e-04, -1.52614375e-05, -4.64253506e-04, ...,\n",
       "          9.68546447e-05,  9.71954214e-05,  1.63949342e-04],\n",
       "        ...,\n",
       "        [ 8.24104500e-05,  2.71828787e-04, -1.59147347e-03, ...,\n",
       "          3.30267212e-04, -2.85070331e-04,  2.50657380e-04],\n",
       "        [-1.05536557e-04,  3.32398049e-04, -1.15939288e-03, ...,\n",
       "          3.65859451e-04, -2.36681430e-04,  1.19094737e-04],\n",
       "        [-2.66053918e-04,  4.13991278e-04, -9.05945431e-04, ...,\n",
       "          3.12143326e-04, -3.36312281e-04,  8.32155201e-05]]],\n",
       "      dtype=float32)>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for src_sample, tgt_sample in dataset.take(1): break\n",
    "\n",
    "lyricist(src_sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b598338c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"text_generator\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding (Embedding)        multiple                  3840256   \n",
      "_________________________________________________________________\n",
      "lstm (LSTM)                  multiple                  5246976   \n",
      "_________________________________________________________________\n",
      "lstm_1 (LSTM)                multiple                  8392704   \n",
      "_________________________________________________________________\n",
      "dense (Dense)                multiple                  15376025  \n",
      "=================================================================\n",
      "Total params: 32,855,961\n",
      "Trainable params: 32,855,961\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "lyricist.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "40bb8c68",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15\n",
      "686/686 [==============================] - 131s 187ms/step - loss: 3.6521\n",
      "Epoch 2/15\n",
      "686/686 [==============================] - 131s 190ms/step - loss: 3.1615\n",
      "Epoch 3/15\n",
      "686/686 [==============================] - 131s 191ms/step - loss: 2.9680\n",
      "Epoch 4/15\n",
      "686/686 [==============================] - 131s 190ms/step - loss: 2.8196\n",
      "Epoch 5/15\n",
      "686/686 [==============================] - 131s 191ms/step - loss: 2.6910\n",
      "Epoch 6/15\n",
      "686/686 [==============================] - 131s 191ms/step - loss: 2.5744\n",
      "Epoch 7/15\n",
      "686/686 [==============================] - 131s 191ms/step - loss: 2.4685\n",
      "Epoch 8/15\n",
      "686/686 [==============================] - 132s 191ms/step - loss: 2.3691\n",
      "Epoch 9/15\n",
      "686/686 [==============================] - 131s 190ms/step - loss: 2.2760\n",
      "Epoch 10/15\n",
      "686/686 [==============================] - 131s 191ms/step - loss: 2.1856\n",
      "Epoch 11/15\n",
      "686/686 [==============================] - 131s 190ms/step - loss: 2.0991\n",
      "Epoch 12/15\n",
      "686/686 [==============================] - 131s 191ms/step - loss: 2.0163\n",
      "Epoch 13/15\n",
      "686/686 [==============================] - 131s 191ms/step - loss: 1.9363\n",
      "Epoch 14/15\n",
      "686/686 [==============================] - 131s 191ms/step - loss: 1.8590\n",
      "Epoch 15/15\n",
      "686/686 [==============================] - 131s 191ms/step - loss: 1.7845\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f160aff79d0>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "optimizer = tf.keras.optimizers.Adam()\n",
    "#Loss\n",
    "loss = tf.keras.losses.SparseCategoricalCrossentropy(\n",
    "    from_logits=True, reduction='none')\n",
    "\n",
    "lyricist.compile(loss=loss, optimizer=optimizer)\n",
    "lyricist.fit(dataset, epochs=15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "799eacc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_text(model, tokenizer, init_sentence=\"<start>\", max_len=20):\n",
    "    test_input = tokenizer.texts_to_sequences([init_sentence])\n",
    "    test_tensor = tf.convert_to_tensor(test_input, dtype=tf.int64)\n",
    "    end_token = tokenizer.word_index[\"<end>\"]\n",
    "\n",
    "    while True:\n",
    "        predict = model(test_tensor) \n",
    "        predict_word = tf.argmax(tf.nn.softmax(predict, axis=-1), axis=-1)[:, -1] \n",
    "        test_tensor = tf.concat([test_tensor, tf.expand_dims(predict_word, axis=0)], axis=-1)\n",
    "\n",
    "        if predict_word.numpy()[0] == end_token: break\n",
    "        if test_tensor.shape[1] >= max_len: break\n",
    "\n",
    "    generated = \"\"\n",
    "\n",
    "    for word_index in test_tensor[0].numpy():\n",
    "        generated += tokenizer.index_word[word_index] + \" \"\n",
    "\n",
    "    return generated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "34d20ac9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<start> she s got me runnin round and round <end> \n"
     ]
    }
   ],
   "source": [
    "lyric = generate_text(lyricist, tokenizer, init_sentence=\"<start> she\", max_len=20)\n",
    "print(lyric)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4ff0709",
   "metadata": {},
   "source": [
    "## 마무리"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44e013b7",
   "metadata": {},
   "source": [
    "* 텍스트 제너레이션 결과에 대해.\n",
    "    * 가사 내용은 그럴 듯하게 생성된 듯 하다. 처음엔 10000개 단어를 기억할 수 있는 tokenizer를 만들었는데, 이 결과와 15000개로 늘렸을 때의 결과는 달랐다. 물론 가사 내용이 변한 것에 새로 학습을 한 것도 있고, 다른 원인이 있을 것이라 생각되지만 tokenizer 수치 변경에도 이유가 있을 것이라 생각한다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1335cc9",
   "metadata": {},
   "source": [
    "* 특수문자 제거\n",
    "    * 문제 없이 제거된 듯 하다. 이 부분에서 좀 답답했는데, 데이터 수가 많아서 눈으로 확인이 어려웠다. 특수 문자를 찾는 코드에 대한 이해가 부족하다고 생각됨."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "261399ab",
   "metadata": {},
   "source": [
    "* 토크나이저 생성, 패딩 처리\n",
    "   * tokenizer에 대한 기본 개념은 어렴풋이 이해가 되지만 이걸 처음부터 혼자 작성한다고 하면 못할 것 같다. 문장을 토큰 단위로 쪼개는 건 알겠고, 학습을 위한 것이라는 것도 알겠는데 학습의 메커니즘이 잘 이해가 가지 않았다. 패딩 또한 같은 맥락으로 문장의 길이를 맞춰주기 위함이라는 건 알지만 근본적인 부분이 이해가 안된다고 해야하나.."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59dfce65",
   "metadata": {},
   "source": [
    "* 모델의 validation loss\n",
    "    * 최종 loss는 1.7241로 루브릭 평가기준이었던 2.2보다는 나은 수치를 기록했다. 최대 토큰 개수 15개 이상인 데이터를 학습에서 제외하기 위해 패딩 max_len을 15로 제한했었는데, 물론 이 방법도 맞게 적용한 건지는 아직 모르지만 이 때문인건지, 아니면 epoch를 충분히 줘서인지 처음부터 2.2 이하의 loss값이 나와서 어려운 문제였는지 잘 모르겠다.  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93d87d58",
   "metadata": {},
   "source": [
    "* 최종적으로\n",
    "    * cv에 비해 가시적으로 바로 볼 수 있는 분야가 아니라는 것을 느꼈다. 아무것도 모르고 4학년 1학기 졸업과제로 했던 영어 리뷰 요약을 어떻게 수행했던 건지 의아할 정도였는데 물론 cv가 쉽다는 건 아니지만 그래도 난 cv가 훨씬 좋은 것 같다. 영어와 한국어를 비롯한 다양한 언어가 존재하고, 관용적인 말도 많은 걸 고려하면 자연어처리 분야는 지금 나한테는 너무 멀게 느껴지는 분야인 듯함..."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
