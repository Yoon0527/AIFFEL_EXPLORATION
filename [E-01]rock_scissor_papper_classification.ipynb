{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "369541f2",
   "metadata": {},
   "source": [
    "# 가위바위보 분류기\n",
    "\n",
    "* 이미지 분류 모델을 만들어 가위바위보를 각각 분류하기\n",
    "\n",
    "* 평가 문항\n",
    "    * 이미지 분류기 모델이 성공적으로 만들어졌는가?\n",
    "    * 오버피팅을 극복하기 위한 적절한 시도가 있었는가?\n",
    "    * 분류모델의 test accuracy가 기준 이상 높게 나왔는가?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79a3e10d",
   "metadata": {},
   "source": [
    "### 1. 데이터 불러오기와 resize\n",
    "(이미지 제작: https://teachablemachine.withgoogle.com/)\n",
    "* 이미지 조작을 위해 PIL 라이브러리 사용\n",
    "* 이미지를 28x28 사이즈로 변환"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4ef83bf3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "import glob\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "61b808ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1501 images to be resized...\n",
      "1501 images resized.\n",
      "\n",
      "\n",
      "1501 images to be resized...\n",
      "1501 images resized.\n",
      "\n",
      "\n",
      "1501 images to be resized...\n",
      "1501 images resized.\n",
      "\n",
      "\n",
      "가위 바위 보 이미지 resize 완료\n"
     ]
    }
   ],
   "source": [
    "def resize_image(img_path):\n",
    "    images = glob.glob(img_path + '/*.jpg')\n",
    "    \n",
    "    print(len(images), 'images to be resized...')\n",
    "    \n",
    "    target_size = (28, 28)\n",
    "    \n",
    "    for img in images:\n",
    "        old_img = Image.open(img)\n",
    "        new_img = old_img.resize(target_size, Image.ANTIALIAS)\n",
    "        new_img.save(img, 'JPEG')\n",
    "        \n",
    "    print(len(images), 'images resized.')\n",
    "    print('\\n')\n",
    "\n",
    "#가위 이미지 resize\n",
    "image_dir_path_scissor = os.getenv('HOME') + '/aiffel/rock_scissor_paper/scissor'\n",
    "resize_image(image_dir_path_scissor)\n",
    "\n",
    "#바위 이미지 resize\n",
    "image_dir_path_rock = os.getenv('HOME') + '/aiffel/rock_scissor_paper/rock'\n",
    "resize_image(image_dir_path_rock)\n",
    "\n",
    "#보 이미지 resize\n",
    "image_dir_path_paper = os.getenv('HOME') + '/aiffel/rock_scissor_paper/paper'\n",
    "resize_image(image_dir_path_paper)\n",
    "\n",
    "print('가위 바위 보 이미지 resize 완료')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9cb42d0a",
   "metadata": {},
   "source": [
    "* **알게된 것**\n",
    "\n",
    "    * **glob.glob():** 사용자가 제시한 조건에 맞는 파일명을 리스트 형식으로 반환한다\n",
    "   \n",
    "    * **Image.ANTIALIAS:** 높은 해상도의 사진 또는 영상을 낮은 해상도로 변환하거나 나타낼 때 깨진 패턴의 형태로 나타나게 되는데 이를 최소화 시켜준다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3258769",
   "metadata": {},
   "source": [
    "### 2. load_data() 함수\n",
    "* 데이터를 읽을 수 있는 함수 만들기\n",
    "* 입력으로 이미지가 있는 폴더 위치를 받고 각각의 클래스로 라벨링 한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c3911a5c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "학습 데이터 (x_train)의 이미지 개수는  4503 입니다.\n",
      "x_train shape: (4503, 28, 28, 3)\n",
      "y_train shape: (4503,)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "def load_data(img_path, number_of_data=4503): #number_of_data에 데이터 총 개수를 입력한다.\n",
    "    img_size = 28\n",
    "    color = 3    \n",
    "    \n",
    "    # 이미지 데이터와 라벨(가위:0, 바위:1, 보:2) 데이터를 담을 행렬 생성\n",
    "    imgs = np.zeros(number_of_data*img_size*img_size*color, dtype = np.int32).reshape(number_of_data, img_size, img_size, color)\n",
    "    labels = np.zeros(number_of_data, dtype = np.int32)\n",
    "    \n",
    "    idx = 0\n",
    "    \n",
    "    for file in glob.glob(img_path + '/scissor/*.jpg'):\n",
    "        img = np.array(Image.open(file), dtype = np.int32)\n",
    "        imgs[idx, :, :, :] = img    #데이터 영역에 이미지 행렬을 복사\n",
    "        labels[idx] = 0   #가위 : 0\n",
    "        idx += 1\n",
    "        \n",
    "    for file in glob.glob(img_path + '/rock/*.jpg'):\n",
    "        img = np.array(Image.open(file), dtype = np.int32)\n",
    "        imgs[idx, :, :, :] = img\n",
    "        labels[idx] = 1    #바위 : 1\n",
    "        idx += 1\n",
    "        \n",
    "    for file in glob.glob(img_path + '/paper/*.jpg'):\n",
    "        img = np.array(Image.open(file), dtype = np.int32)\n",
    "        imgs[idx, :, :, :] = img\n",
    "        labels[idx] = 2   #보 : 2\n",
    "        idx += 1\n",
    "        \n",
    "    print(\"학습 데이터 (x_train)의 이미지 개수는 \", idx, \"입니다.\")\n",
    "    return imgs, labels\n",
    "\n",
    "\n",
    "image_dir_path = os.getenv('HOME') + \"/aiffel/rock_scissor_paper\"\n",
    "(x_train, y_train) = load_data(image_dir_path)\n",
    "x_train_norm = x_train/255.0    #입력을 0~1 사이의 값으로 정규화\n",
    "\n",
    "print('x_train shape: {}'.format(x_train.shape))\n",
    "print('y_train shape: {}'.format(y_train.shape))\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d51a78ab",
   "metadata": {},
   "source": [
    "* **알게된 것**\n",
    "\n",
    "    * **라벨이란:** 원본 데이터에 대한 추가적인 정보가 포함된 '마커', 중요한 것은 데이터가 아닌 점이다.\n",
    "        * 반려동물 이미지에서 강아지는 강아지, 고양이는 고양이로 지정하는 등\n",
    "    * **color=3인 이유:** rgb값이라서\n",
    "    \n",
    "    * **int32:** numpy의 ndarray(다차원 행렬 구조)는 dtype으로 저장되는데, int32는 numpy의 주요 데이터형 중 하나이다. (https://engineer-mole.tistory.com/85)\n",
    "    \n",
    "    * **255.0을 나누는 이유:** 인공지능 모델을 훈련시키고 사용할 때, 일반적으로 입력은 0에서1 사이의 값으로 정규화 시켜주는 것이 좋은데, 각 픽셀의 값이 0~255 사이 범위에 있기 때문에 255.0으로 나누어준다\n",
    "    \n",
    "    * **x_train, y_train으로 데이터를 나누는 이유:** train 데이터를 train 데이터와 validation 데이터로 나누는 용도\n",
    "        * 학습은 보통 train데이터와 validation데이터로 이루어지고, 학습이 완료되면 test 데이터를 사용한다.\n",
    "        (https://lsjsj92.tistory.com/545)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8020062e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "라벨:  0\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.imshow(x_train[0])\n",
    "print('라벨: ', y_train[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f186172",
   "metadata": {},
   "source": [
    "### 3. 딥러닝 네트워크 설계하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8ca0bb6e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d (Conv2D)              (None, 26, 26, 32)        896       \n",
      "_________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D) (None, 26, 26, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 24, 24, 32)        9248      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 12, 12, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 10, 10, 64)        18496     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 5, 5, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 3, 3, 64)          36928     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2 (None, 1, 1, 64)          0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 512)               33280     \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 3)                 1539      \n",
      "=================================================================\n",
      "Total params: 100,387\n",
      "Trainable params: 100,387\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import numpy as np\n",
    "from tensorflow.keras.layers import Dropout\n",
    "\n",
    "# 파라미터\n",
    "\n",
    "n_channel_1=32\n",
    "n_channel_2=32\n",
    "n_channel_3=64\n",
    "n_dense=512\n",
    "n_train_epoch=15\n",
    "\n",
    "model=keras.models.Sequential()\n",
    "\n",
    "model.add(keras.layers.Conv2D(n_channel_1, (3,3),  activation='relu', input_shape=(28,28,3)))\n",
    "model.add(keras.layers.MaxPool2D(1,1))\n",
    "\n",
    "\n",
    "model.add(keras.layers.Conv2D(n_channel_2, (3,3),  activation='relu'))\n",
    "model.add(keras.layers.MaxPooling2D((2,2)))\n",
    "\n",
    "\n",
    "model.add(keras.layers.Conv2D(n_channel_3, (3,3),  activation='relu'))\n",
    "model.add(keras.layers.MaxPooling2D((2,2)))\n",
    "\n",
    "model.add(keras.layers.Conv2D(n_channel_3, (3,3),  activation='relu'))\n",
    "model.add(keras.layers.MaxPooling2D((2,2)))\n",
    "\n",
    "model.add(keras.layers.Flatten())\n",
    "model.add(Dropout(0.5))\n",
    "model.add(keras.layers.Dense(n_dense, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(keras.layers.Dense(3, activation='softmax'))\n",
    "\n",
    "\n",
    "'''\n",
    "model = keras.Sequential()\n",
    "\n",
    "model.add(keras.layers.Conv2D(n_channel_1, (3, 3),  activation='relu', input_shape=(28,28,3)))\n",
    "model.add(keras.layers.MaxPool2D(1,1))\n",
    "\n",
    "\n",
    "model.add(keras.layers.Conv2D(n_channel_2, (3, 3),  activation='relu'))\n",
    "model.add(keras.layers.MaxPooling2D((2,2)))\n",
    "\n",
    "\n",
    "model.add(keras.layers.Conv2D(n_channel_3, (3, 3),  activation='relu'))\n",
    "model.add(keras.layers.MaxPooling2D((2,2)))\n",
    "\n",
    "\n",
    "model.add(keras.layers.Flatten())\n",
    "model.add(Dropout(0.5))\n",
    "model.add(keras.layers.Dense(units=128, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(keras.layers.Dense(units=64, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(keras.layers.Dense(units=3, activation = 'softmax'))\n",
    "'''\n",
    "\n",
    "#모델 요약\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01e09bf8",
   "metadata": {},
   "source": [
    "* **알게된 것:**\n",
    "    * **sequentialAPI:** 간단하게 딥러닝 모델을 만들 수 있는 방법으로, 미리 정의된 딥러닝 레이어를 쉽게 추가할 수 있다. 단, 개발의 자유도는 많이 떨어진다.\n",
    "    * **convolution(conv2D):** convolution이란 convolution layer의 크기 만큼 이동시키면서 겹쳐지는 부분의 각 원소의 값을 곱해서 모두 더한 값을 출력하는 층이다. 이미지를 인식시킬 때, 주변 값들의 관계를 알아내기 위해서 적용한다.\n",
    "    * **MaxPooling**: Pooling은 차례로 처리되는 데이터의 크기를 줄이는 것을 말하고, MaxPooling은 해당 영역에서 최댓값을 찾는 방법이다.\n",
    "        * AveragePooling은 해당 영역에서 평균값을 계산하는 방법이다.\n",
    "        * pooling을 하는 이유: **차원을 감소시키기 위해!!** 왜냐면, 더 높은 정확도를 위해서는 필터가 많아야 함. 필터가 많아지면,\n",
    "            * Feature Map 늘어나서 안좋음 -> dimension이 늘어남 -> 파라미터의 수가 늘어난다\n",
    "                * 오버피팅 문제, 모델 사이즈와 레이턴시에도 영향을 미침 -> 차원을 감소시킬 필요성\n",
    "        (https://underflow101.tistory.com/41)\n",
    "        \n",
    "    * **activation 함수:** 비선형 시스템으로 만들기 위해(인공지능 관련 AND, OR, XOR 참고)\n",
    "    (https://ganghee-lee.tistory.com/30)\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd7735c7",
   "metadata": {},
   "source": [
    "* **LeNet?**\n",
    "    * 이번 exploration에서 사용한 모델이 LeNet이라는 걸 알았는데, 합성곱 신경망을 활용하는 LeNet은 LeNet-1에서 LeNet-5까지 개발되었다.\n",
    "    (https://www.hellot.net/mobile/article.html?no=42920)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e913b70",
   "metadata": {},
   "source": [
    "### 4. 딥러닝 네트워크 학습시키기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "05b7aea6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15\n",
      "141/141 [==============================] - 4s 5ms/step - loss: 0.9525 - accuracy: 0.6904\n",
      "Epoch 2/15\n",
      "141/141 [==============================] - 1s 4ms/step - loss: 0.0434 - accuracy: 0.9845\n",
      "Epoch 3/15\n",
      "141/141 [==============================] - 1s 4ms/step - loss: 0.0340 - accuracy: 0.9878\n",
      "Epoch 4/15\n",
      "141/141 [==============================] - 1s 4ms/step - loss: 0.0190 - accuracy: 0.9916\n",
      "Epoch 5/15\n",
      "141/141 [==============================] - 1s 4ms/step - loss: 0.0087 - accuracy: 0.9978\n",
      "Epoch 6/15\n",
      "141/141 [==============================] - 1s 4ms/step - loss: 0.0071 - accuracy: 0.9978\n",
      "Epoch 7/15\n",
      "141/141 [==============================] - 1s 4ms/step - loss: 0.0021 - accuracy: 0.9996\n",
      "Epoch 8/15\n",
      "141/141 [==============================] - 1s 4ms/step - loss: 0.0030 - accuracy: 0.9987\n",
      "Epoch 9/15\n",
      "141/141 [==============================] - 1s 4ms/step - loss: 0.0071 - accuracy: 0.9980\n",
      "Epoch 10/15\n",
      "141/141 [==============================] - 1s 4ms/step - loss: 0.0621 - accuracy: 0.9876\n",
      "Epoch 11/15\n",
      "141/141 [==============================] - 1s 4ms/step - loss: 0.0016 - accuracy: 0.9991\n",
      "Epoch 12/15\n",
      "141/141 [==============================] - 1s 4ms/step - loss: 0.0015 - accuracy: 0.9996\n",
      "Epoch 13/15\n",
      "141/141 [==============================] - 1s 4ms/step - loss: 9.5068e-04 - accuracy: 0.9996\n",
      "Epoch 14/15\n",
      "141/141 [==============================] - 1s 4ms/step - loss: 0.0011 - accuracy: 0.9998\n",
      "Epoch 15/15\n",
      "141/141 [==============================] - 1s 4ms/step - loss: 3.6016e-04 - accuracy: 1.0000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fb6b18fa0a0>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 모델 훈련\n",
    "model.compile(optimizer='adam',\n",
    "             loss='sparse_categorical_crossentropy',\n",
    "             metrics=['accuracy'])\n",
    "\n",
    "model.fit(x_train, y_train, epochs=n_train_epoch)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59a2673d",
   "metadata": {},
   "source": [
    "* **알게된 것**\n",
    "    * **optimizer:** 손실함수의 결과값을 최소화하는 모델의 파라미터(가중치)를 찾는 것 (https://blog.naver.com/another0430/222063836606)\n",
    "    * **손실함수(loss):** 데이터를 토대로 산출한 모델의 예측 값과 실제 값의 차이를 표현하는 지표\n",
    "    * **평가지표(metric):** 검증셋에서 훈련된 모델의 성능을 평가할 때 어떤 평가지표로 평가할지를 결정\n",
    "    (https://bskyvision.com/740)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bfd5780",
   "metadata": {},
   "source": [
    "### 5. 테스트"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ffe3ebdd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "201 images to be resized...\n",
      "201 images resized.\n",
      "\n",
      "\n",
      "201 images to be resized...\n",
      "201 images resized.\n",
      "\n",
      "\n",
      "202 images to be resized...\n",
      "202 images resized.\n",
      "\n",
      "\n",
      "가위 바위 보 테스트 이미지 resize 완료\n"
     ]
    }
   ],
   "source": [
    "def resize_image(img_path):\n",
    "    images = glob.glob(img_path + '/*.jpg')\n",
    "    \n",
    "    print(len(images), 'images to be resized...')\n",
    "    \n",
    "    target_size = (28, 28)\n",
    "    \n",
    "    for img in images:\n",
    "        old_img = Image.open(img)\n",
    "        new_img = old_img.resize(target_size, Image.ANTIALIAS)\n",
    "        new_img.save(img, 'JPEG')\n",
    "        \n",
    "    print(len(images), 'images resized.')\n",
    "    print('\\n')\n",
    "\n",
    "#가위 이미지 resize\n",
    "image_dir_path_scissor = os.getenv('HOME') + '/aiffel/rock_scissor_paper/test/scissor'\n",
    "resize_image(image_dir_path_scissor)\n",
    "\n",
    "#바위 이미지 resize\n",
    "image_dir_path_rock = os.getenv('HOME') + '/aiffel/rock_scissor_paper/test/rock'\n",
    "resize_image(image_dir_path_rock)\n",
    "\n",
    "#보 이미지 resize\n",
    "image_dir_path_paper = os.getenv('HOME') + '/aiffel/rock_scissor_paper/test/paper'\n",
    "resize_image(image_dir_path_paper)\n",
    "\n",
    "print('가위 바위 보 테스트 이미지 resize 완료')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "56fb84f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "테스트 데이터 (x_test)의 이미지 개수는  604 입니다.\n",
      "x_test shape: (604, 28, 28, 3)\n",
      "y_test shape: (604,)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "def load_data(img_path, number_of_data=604): #number_of_data에 데이터 총 개수를 입력한다.\n",
    "    img_size = 28\n",
    "    color = 3    \n",
    "    \n",
    "    # 이미지 데이터와 라벨(가위:0, 바위:1, 보:2) 데이터를 담을 행렬 생성\n",
    "    imgs = np.zeros(number_of_data*img_size*img_size*color, dtype = np.int32).reshape(number_of_data, img_size, img_size, color)\n",
    "    labels = np.zeros(number_of_data, dtype = np.int32)\n",
    "    \n",
    "    idx = 0\n",
    "    \n",
    "    for file in glob.glob(img_path + '/scissor/*.jpg'):\n",
    "        img = np.array(Image.open(file), dtype = np.int32)\n",
    "        imgs[idx, :, :, :] = img    #데이터 영역에 이미지 행렬을 복사\n",
    "        labels[idx] = 0   #가위 : 0\n",
    "        idx += 1\n",
    "        \n",
    "    for file in glob.glob(img_path + '/rock/*.jpg'):\n",
    "        img = np.array(Image.open(file), dtype = np.int32)\n",
    "        imgs[idx, :, :, :] = img\n",
    "        labels[idx] = 1    #바위 : 1\n",
    "        idx += 1\n",
    "        \n",
    "    for file in glob.glob(img_path + '/paper/*.jpg'):\n",
    "        img = np.array(Image.open(file), dtype = np.int32)\n",
    "        imgs[idx, :, :, :] = img\n",
    "        labels[idx] = 2   #보 : 2\n",
    "        idx += 1\n",
    "        \n",
    "    print(\"테스트 데이터 (x_test)의 이미지 개수는 \", idx, \"입니다.\")\n",
    "    return imgs, labels\n",
    "\n",
    "\n",
    "image_dir_path = os.getenv('HOME') + \"/aiffel/rock_scissor_paper/test\"\n",
    "(x_test, y_test) = load_data(image_dir_path)\n",
    "x_test_norm = x_train/255.0    #입력을 0~1 사이의 값으로 정규화\n",
    "\n",
    "print('x_test shape: {}'.format(x_test.shape))\n",
    "print('y_test shape: {}'.format(y_test.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "abe461d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19/19 - 0s - loss: 9.1442 - accuracy: 0.6507\n",
      "test_loss: 9.144172668457031 \n",
      "test_accuracy: 0.6506622433662415\n"
     ]
    }
   ],
   "source": [
    "test_loss, test_accuracy = model.evaluate(x_test,y_test, verbose=2)\n",
    "print(\"test_loss: {} \".format(test_loss))\n",
    "print(\"test_accuracy: {}\".format(test_accuracy))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0f68df6",
   "metadata": {},
   "source": [
    "* **정확도를 올리기 위해** (0.3444 - 0.5695 - 0.4636 ...-0.6507\n",
    "    * **데이터셋 늘리기:** 동기분들 데이터셋 활용 -> 이후 직접 찍은 이미지들로만 재구성\n",
    "    * **하이퍼 파라미터 값 바꾸기**\n",
    "    * **Dropout 추가해보기:** 오버피팅을 방지\n",
    "    * **다양한 모델 layer 구성 변경 시도:** \bconv2d와 pooling layer를 추가\n",
    "    * **데이터셋 재구성:** 확실하게 구별 가능한 이미지로 재구성, 테스트 데이터셋 확인\n",
    "    * **LeNet-5 적용 시도:** 이미지 resize를 (32, 32)로 늘린 후 모델에 입력해봤으나 모델 layer 구성 자체가 LeNet-1과 크게 다르지 않아서인지 정확도에는 큰 변화가 보이지 않았다.(제대로 LeNet-5를 구현했는지는 모르겠음. 더 공부해봐야 알 것 같다.)\n",
    "\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5b75a3e",
   "metadata": {},
   "source": [
    "* **느낀점**\n",
    "    * **하이퍼 파라미터를 높게 잡아준다고 무조건 좋은 것은 아니다.** 특징을 많이 찾아내더라도 유의미한 특징만을 찾을 거라는 보장이 없다. 파라미터 각각의 의미에 대해 조금 더 공부해볼 필요성을 느끼게 되었다.\n",
    "    \n",
    "    * **데이터셋의 볼륨이 큰 것이 높은 정확도로 가는 지름길은 아니다.** 과적합의 위험도 있고 지금 당장 dropdout이나 과적합을 피하기 위한 방법에 대한 지식이 충분하지 않아서 활용을 제대로 못하고 있는 느낌을 받았다. 모델을 구성하는 레이어와 레이어에 인자들의 의미를 이해하고 조절한다면 조금이라도 더 높은 정확도를 도출할 수 있을 것 같다.\n",
    "    \n",
    "    * **분류 모델 중 LeNet에 대해 조금 더 알게 되었다.** 1단계부터 5단계까지 발전해온 것을 알았고, 이미지 사이즈가 커지면 학습 시간이 오래 걸리지만 이 점이 정확도에 큰 연관이 있는지는 조금 더 공부해야 확실히 이해할 것 같다. 아직은 LeNet-1과 LeNet-5의 차이점 중 이미지 사이즈 크기 외에는 내가 이해할 수 있는 범위가 아니어서 이 역시 조금 더 공부한 후에 다시 읽어봐야할 것 같다."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
